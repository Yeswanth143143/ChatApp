{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.cosmos import CosmosClient,PartitionKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries=[\n",
    "    {\n",
    "  \"id\": \"conversation-1\",\n",
    "\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"Good morning! How are you feeling today?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I’m feeling anxious about my workload.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"I'm here to help. Can we break the workload into smaller tasks?\"\n",
    "    }\n",
    "  ],\n",
    "  \"alternative_responses\": [\n",
    "    {\n",
    "      \"original_message\": \"I’m feeling anxious about my workload.\",\n",
    "      \"responses\": [\n",
    "        {\n",
    "          \"alternative_response\": \"That sounds tough. Let’s talk about ways to manage it.\",\n",
    "          \"comment\": \"Acknowledges the user's feelings and offers help.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Would it help to list and prioritize your tasks together?\",\n",
    "          \"comment\": \"Suggests a constructive approach to reduce anxiety.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Take a deep breath. We can handle this one step at a time.\",\n",
    "          \"comment\": \"Encourages calming techniques and stepwise management.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"session_start_time\": \"2024-11-18T09:00:00Z\",\n",
    "    \"session_end_time\": \"2024-11-18T09:30:00Z\",\n",
    "    \"user_id\": \"user-1\"\n",
    "  }\n",
    "}\n",
    ",\n",
    "{\n",
    "  \"id\": \"conversation-2\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"Hi there! What’s on your mind today?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I’m having trouble sleeping lately.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"Sleep troubles can be frustrating. Have you tried relaxing before bedtime?\"\n",
    "    }\n",
    "  ],\n",
    "  \"alternative_responses\": [\n",
    "    {\n",
    "      \"original_message\": \"I’m having trouble sleeping lately.\",\n",
    "      \"responses\": [\n",
    "        {\n",
    "          \"alternative_response\": \"That sounds difficult. Could you tell me more about your sleep routine?\",\n",
    "          \"comment\": \"Encourages the user to share details for better support.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Sometimes, avoiding screens an hour before bed can help. Would you like tips on this?\",\n",
    "          \"comment\": \"Provides practical advice for better sleep.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Would you like to try a mindfulness exercise before sleeping?\",\n",
    "          \"comment\": \"Suggests a calming practice to aid sleep.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"session_start_time\": \"2024-11-18T11:30:00Z\",\n",
    "    \"session_end_time\": \"2024-11-18T12:00:00Z\",\n",
    "    \"user_id\": \"user-2\"\n",
    "  }\n",
    "}\n",
    ",\n",
    "{\n",
    "  \"id\": \"conversation-3\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I feel like I’m failing at everything.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"I’m sorry you feel this way. Let’s explore what’s making you feel like this.\"\n",
    "    }\n",
    "  ],\n",
    "  \"alternative_responses\": [\n",
    "    {\n",
    "      \"original_message\": \"I feel like I’m failing at everything.\",\n",
    "      \"responses\": [\n",
    "        {\n",
    "          \"alternative_response\": \"That sounds really hard. Could you share one thing you feel isn’t working?\",\n",
    "          \"comment\": \"Encourages sharing specific concerns.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Failure is a part of growth. Let’s find ways to reframe this.\",\n",
    "          \"comment\": \"Normalizes failure and offers perspective.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Would you like help in identifying your strengths?\",\n",
    "          \"comment\": \"Shifts focus to strengths rather than perceived failures.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"session_start_time\": \"2024-11-18T15:00:00Z\",\n",
    "    \"session_end_time\": \"2024-11-18T15:20:00Z\",\n",
    "    \"user_id\": \"user-3\"\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"id\": \"conversation-4\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"How are you coping with the challenges you mentioned last time?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I’m trying, but it feels overwhelming.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"Let’s tackle one thing at a time. What’s the most pressing issue right now?\"\n",
    "    }\n",
    "  ],\n",
    "  \"alternative_responses\": [\n",
    "    {\n",
    "      \"original_message\": \"I’m trying, but it feels overwhelming.\",\n",
    "      \"responses\": [\n",
    "        {\n",
    "          \"alternative_response\": \"I understand. Overwhelm can feel like too much. Let’s prioritize together.\",\n",
    "          \"comment\": \"Validates the feeling and offers help.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"It’s okay to take small steps. Let’s focus on just the next step.\",\n",
    "          \"comment\": \"Encourages gradual progress.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Could taking a short break help you reset?\",\n",
    "          \"comment\": \"Suggests a simple strategy to manage overwhelm.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"session_start_time\": \"2024-11-18T17:00:00Z\",\n",
    "    \"session_end_time\": \"2024-11-18T17:30:00Z\",\n",
    "    \"user_id\": \"user-4\"\n",
    "  }\n",
    "}\n",
    ",\n",
    "{\n",
    "  \"id\": \"conversation-5\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"What’s one thing that made you smile today?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I saw a beautiful sunset.\"\n",
    "    }\n",
    "  ],\n",
    "  \"alternative_responses\": [\n",
    "    {\n",
    "      \"original_message\": \"I saw a beautiful sunset.\",\n",
    "      \"responses\": [\n",
    "        {\n",
    "          \"alternative_response\": \"That sounds wonderful. What colors did you see?\",\n",
    "          \"comment\": \"Encourages the user to relive the positive experience.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Sunsets can be so calming. Did it help you feel at ease?\",\n",
    "          \"comment\": \"Connects the experience to emotional well-being.\"\n",
    "        },\n",
    "        {\n",
    "          \"alternative_response\": \"Would you like to explore ways to capture such moments more often?\",\n",
    "          \"comment\": \"Suggests finding joy in simple experiences.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"session_start_time\": \"2024-11-18T20:00:00Z\",\n",
    "    \"session_end_time\": \"2024-11-18T20:10:00Z\",\n",
    "    \"user_id\": \"user-5\"\n",
    "  }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def create_items(conversations):\n",
    "    client=CosmosClient(url=os.getenv(\"COSMOS_URI\"),credential=os.getenv(\"COSMOS_KEY\"))\n",
    "    database=client.create_database_if_not_exists(id=\"ChatApp\")\n",
    "    container=database.create_container_if_not_exists(id=\"ChatConversation\",partition_key=PartitionKey(path=\"/id\"),offer_throughput=400)\n",
    "    for chat in conversations:\n",
    "        container.create_item(body=chat)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create_items(dictionaries)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    ComplexField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataContainer,\n",
    "    IndexingSchedule,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchIndexerSkillset,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    VectorSearchAlgorithmKind, VectorSearchAlgorithmMetric,LexicalAnalyzer,KeywordTokenizer,CustomAnalyzer, KeywordTokenizerV2\n",
    ")\n",
    "from datetime import timedelta\n",
    "from openai import AzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndexerIndexProjection,SearchIndexerIndexProjectionSelector, SearchIndexerIndexProjectionsParameters, IndexProjectionMode,CognitiveServicesAccountKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clients\n",
    "indexer_client=SearchIndexerClient(endpoint=os.getenv(\"SEARCH_ENDPOINT\"),credential=AzureKeyCredential(os.getenv(\"SEARCH_KEY_CREDENTIAL\")))\n",
    "index_client=SearchIndexClient(endpoint=os.getenv(\"SEARCH_ENDPOINT\"),credential=AzureKeyCredential(os.getenv(\"SEARCH_KEY_CREDENTIAL\")))\n",
    "search_client=SearchClient(endpoint=os.getenv(\"SEARCH_ENDPOINT\"),credential=AzureKeyCredential(os.getenv(\"SEARCH_KEY_CREDENTIAL\")),index_name=\"chat-rag\")\n",
    "openai_client=AzureOpenAI(api_key=os.getenv(\"AZURE_OPENAI_KEY\"),azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes.models._index.SearchIndex at 0x20388130340>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields=[\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),\n",
    "    #SearchableField(name=\"messages\",type=SearchFieldDataType.String,collection=True),\n",
    "    #SimpleField(name=\"source_id\", type=SearchFieldDataType.String,filterable=True),\n",
    "    ComplexField(name=\"messages\", fields=[\n",
    "    SearchableField(name=\"role\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String)\n",
    "]),\n",
    "    #SearchableField(name=\"alternative_responses\",type=SearchFieldDataType.String,collection=True),\n",
    "    #SimpleField(name=\"metadata\",type=SearchFieldDataType.String,filterable=True),\n",
    "    ComplexField(name=\"metadata\", fields=[\n",
    "    SimpleField(name=\"session_start_time\", type=SearchFieldDataType.DateTimeOffset),\n",
    "    SimpleField(name=\"session_end_time\", type=SearchFieldDataType.DateTimeOffset),\n",
    "    SimpleField(name=\"user_id\", type=SearchFieldDataType.String)\n",
    "]),\n",
    "    ComplexField(name=\"alternative_responses\", fields=[\n",
    "    SearchableField(name=\"original_message\", type=SearchFieldDataType.String),\n",
    "    ComplexField(name=\"responses\", fields=[\n",
    "        SearchableField(name=\"alternative_response\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"comment\", type=SearchFieldDataType.String)\n",
    "    ])\n",
    "]),\n",
    "    #SearchField(name=\"messages_embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),vector_search_dimensions=1536, vector_search_profile_name=\"my-vector-config\"),\n",
    "    SearchField(name=\"alternative_responses_embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),vector_search_dimensions=1536, vector_search_profile_name=\"my-vector-config\"),\n",
    "    SearchField(name=\"chunck_id\",type=SearchFieldDataType.String,key=True,facetable=False,filterable=True,sortable=True,analyzer_name=\"keyword\"),\n",
    "    ]\n",
    "\n",
    "vector_search = VectorSearch(  \n",
    "     algorithms=[  \n",
    "         HnswAlgorithmConfiguration(name=\"myHnsw\",kind=VectorSearchAlgorithmKind.HNSW,\n",
    "         parameters={\n",
    "                        \"m\": 4,\n",
    "                        \"efConstruction\": 400,\n",
    "                        \"efSearch\": 500,\n",
    "                        \"metric\": VectorSearchAlgorithmMetric.COSINE\n",
    "                    }\n",
    " ) ],  \n",
    "     profiles=[  \n",
    "         VectorSearchProfile(  \n",
    "             name=\"my-vector-config\",  \n",
    "             algorithm_configuration_name=\"myHnsw\",  \n",
    "             vectorizer_name=\"myOpenAI\",  \n",
    "         )\n",
    "     ],\n",
    "     vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"myOpenAI\",  # Custom name for the vectorizer\n",
    "            kind=\"azureOpenAI\",  # Type of vectorizer (Azure OpenAI)\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=os.getenv(\"OPENAI_KEY\"),  # Azure OpenAI resource URL  # Name of the model deployment\n",
    "                deployment_name=os.getenv(\"EMBEDING_DEPLOYMENT_NAME\"),\n",
    "                model_name=os.getenv(\"EMBEDING_MODEL_NAME\"),  # Embedding model name\n",
    "                api_key=os.getenv(\"AZURE_EMBEDING_KEY\")\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create or update index\n",
    "index = SearchIndex(name=\"chat-rag\", fields=fields, vector_search=vector_search)\n",
    "index_client.create_or_update_index(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data source (assuming CosmosDB)\n",
    "container = SearchIndexerDataContainer(name=\"ChatConversation\")\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=\"chat-rag-datasource\",\n",
    "    type=\"cosmosdb\",\n",
    "    container=container,\n",
    "    connection_string=os.getenv(\"COSMOS_CONNECTION_STRING\"))\n",
    "data_source=indexer_client.create_or_update_data_source_connection(data_source_connection=data_source_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_skill_for_alternative_responses = AzureOpenAIEmbeddingSkill(\n",
    "    name=\"embedding-alternative-responses\",\n",
    "    description=\"Generate embeddings for alternative responses using Azure OpenAI\",\n",
    "    context=\"/document\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/alternative_responses\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"alternative_response_embedding\")\n",
    "    ],\n",
    "    resource_url=os.getenv(\"OPENAI_KEY\"),\n",
    "    model_name=os.getenv(\"EMBEDING_MODEL_NAME\"),\n",
    "    deployment_name=os.getenv(\"EMBEDING_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "\"\"\"embedding_skill_for_messages = AzureOpenAIEmbeddingSkill(\n",
    "    name=\"embedding-messages\",\n",
    "    description=\"Generate embeddings for messages using Azure OpenAI\",\n",
    "    context=\"/document\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/messages\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"messages_embedding\")\n",
    "    ],\n",
    "    resource_url=os.getenv(\"OPENAI_KEY\"),\n",
    "    model_name=os.getenv(\"EMBEDING_MODEL_NAME\"),\n",
    "    deployment_name=os.getenv(\"EMBEDING_DEPLOYMENT_NAME\")\n",
    ")\"\"\"\n",
    "\n",
    "# Define field mappings\n",
    "field_mappings = [\n",
    "    #InputFieldMappingEntry(name=\"original_id\", source=\"/id\"),\n",
    "    InputFieldMappingEntry(name=\"messages\", source=\"/messages\"),\n",
    "    InputFieldMappingEntry(name=\"alternative_responses\", source=\"/alternative_responses\"),\n",
    "    InputFieldMappingEntry(name=\"metadata\", source=\"/metadata\"),\n",
    "    #InputFieldMappingEntry(name=\"messages_embedding\", source=\"/messages_embedding\"),\n",
    "    InputFieldMappingEntry(name=\"alternative_responses_embedding\", source=\"/alternative_responses_embedding\")\n",
    "]\n",
    "\n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index.name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document\",  \n",
    "            mappings=field_mappings,  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS \n",
    ") \n",
    ")\n",
    "cognitive_services_account = CognitiveServicesAccountKey(key=os.getenv(\"ALL_MULTI_PURPOSE_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'my-skillset', 'description': 'Skillset for generating embeddings', 'skills': [<azure.search.documents.indexes._generated.models._models_py3.AzureOpenAIEmbeddingSkill object at 0x000002038A8A3880>], 'cognitive_services_account': <azure.search.documents.indexes._generated.models._models_py3.CognitiveServicesAccountKey object at 0x000002038A8A2E00>, 'knowledge_store': None, 'index_projection': <azure.search.documents.indexes._generated.models._models_py3.SearchIndexerIndexProjection object at 0x000002038A8F8CA0>, 'e_tag': None, 'encryption_key': None}\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset\n",
    "skillset = SearchIndexerSkillset(\n",
    "    name=\"my-skillset\",\n",
    "    description=\"Skillset for generating embeddings\",\n",
    "    skills=[embedding_skill_for_alternative_responses],\n",
    "    cognitive_services_account=cognitive_services_account,\n",
    "    index_projection=index_projections\n",
    ")\n",
    "print(skillset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes.models._models.SearchIndexerSkillset at 0x20386bc2770>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create or update the skillset\n",
    "skillset_client=SearchIndexerClient(endpoint=os.getenv(\"SEARCH_ENDPOINT\"),credential=AzureKeyCredential(os.getenv(\"SEARCH_KEY_CREDENTIAL\")))\n",
    "skillset_client.create_or_update_skillset(skillset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-skillset\n"
     ]
    }
   ],
   "source": [
    "print(skillset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes.models._models.SearchIndexer at 0x20387db86a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = SearchIndexer(\n",
    "    name=\"chat-indexer\",  \n",
    "    description=\"Indexer to generate embeddings\",  \n",
    "    skillset_name=skillset.name,  \n",
    "    target_index_name=\"chat-rag\",  \n",
    "    data_source_name=data_source.name,\n",
    ")\n",
    "indexer_client.create_or_update_indexer(indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iterator object azure.core.paging.ItemPaged at 0x1a1feb22d10>\n"
     ]
    }
   ],
   "source": [
    "query=\"I am feeling bad\" \n",
    "results = search_client.search(  \n",
    "    search_text=query, \n",
    "    select=[\"alternative_responses\"],\n",
    "    top=1,\n",
    "    search_fields=[\"alternative_responses/*/\"]\n",
    ")  \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "() The field 'alternative_responses' in the search field list is not searchable.\r\nParameter name: searchFields\nCode: \nMessage: The field 'alternative_responses' in the search field list is not searchable.\r\nParameter name: searchFields",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:  \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@search.score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternative_responses\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\azure\\search\\documents\\_paging.py:54\u001b[0m, in \u001b[0;36mSearchItemPaged.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m     first_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_iterator_instance()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(first_iterator)\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_page_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\azure\\core\\paging.py:75\u001b[0m, in \u001b[0;36mPageIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of paging\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\azure\\search\\documents\\_paging.py:125\u001b[0m, in \u001b[0;36mSearchPageIterator._get_next_cb\u001b[1;34m(self, continuation_token)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_next_cb\u001b[39m(\u001b[38;5;28mself\u001b[39m, continuation_token):\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continuation_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39msearch_post(search_request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_query\u001b[38;5;241m.\u001b[39mrequest, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m    127\u001b[0m     _next_link, next_page_request \u001b[38;5;241m=\u001b[39m unpack_continuation_token(continuation_token)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39msearch_post(search_request\u001b[38;5;241m=\u001b[39mnext_page_request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\azure\\search\\documents\\_generated\\operations\\_documents_operations.py:754\u001b[0m, in \u001b[0;36mDocumentsOperations.search_post\u001b[1;34m(self, search_request, request_options, **kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[0;32m    753\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[1;32m--> 754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n\u001b[0;32m    756\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearchDocumentsResult\u001b[39m\u001b[38;5;124m\"\u001b[39m, pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: () The field 'alternative_responses' in the search field list is not searchable.\r\nParameter name: searchFields\nCode: \nMessage: The field 'alternative_responses' in the search field list is not searchable.\r\nParameter name: searchFields"
     ]
    }
   ],
   "source": [
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(result['alternative_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iterator object azure.core.paging.ItemPaged at 0x27f53f00b50>\n"
     ]
    }
   ],
   "source": [
    "query=\"I am feeling overwhelming\" \n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"embedding\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    #search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"alternative_responses\"],\n",
    "    top=1,\n",
    "    search_fields=[\"alternative_responses\"]\n",
    ")  \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'kind': 'text', 'k_nearest_neighbors': 50, 'fields': 'embedding', 'exhaustive': None, 'oversampling': None, 'weight': None, 'text': 'I am feeling overwhelming'}\n"
     ]
    }
   ],
   "source": [
    "list(results)\n",
    "print(vector_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(result['alternative_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_embeddings(text):\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"  # Make sure this matches your deployment name\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def hybrid_search(query, top_k=3):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    \n",
    "    # Perform hybrid search\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        #vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        vector_fields=\"embedding\",\n",
    "        select=\"messages,alternative_responses\",\n",
    "        query_type=\"semantic\",\n",
    "        #semantic_configuration_name=\"my-vector-config\"  # Make sure you have this configured in your index\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(query, top_k=3):\n",
    "    # Perform hybrid search\n",
    "    search_results = hybrid_search(query, top_k)\n",
    "    print(search_results)\n",
    "    # Prepare context from search results\n",
    "    context = \"\\n\".join([result['messages'] for result in search_results])\n",
    "    \n",
    "    # Generate response using GPT model\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the following context to answer the user's question.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Unsupported data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am having a bad day\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrag_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mrag_query\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrag_query\u001b[39m(query, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Perform hybrid search\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     search_results \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(search_results)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Prepare context from search results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36mhybrid_search\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhybrid_search\u001b[39m(query, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Generate embedding for the query\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Perform hybrid search\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     results \u001b[38;5;241m=\u001b[39m search_client\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     14\u001b[0m         search_text\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m#vector=query_embedding,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;66;03m#semantic_configuration_name=\"my-vector-config\"  # Make sure you have this configured in your index\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_embeddings\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-embedding-ada-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Make sure this matches your deployment name\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GenAI\\Projects\\ChatApp\\chatapp\\lib\\site-packages\\openai\\_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1068\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Unsupported data type"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"I am having a bad day\"\n",
    "answer = rag_query(query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
